---
title: "Tick Simulation Base"
author: "Piper Zimmerman"
date: "September 29, 2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(nimble)
library(HDInterval)
library(MCMCvis)
library(coda) # makes diagnostic plots
library(IDPmisc) # makes nice colored pairs plots to look at joint posteriors
library("matrixStats")
library("truncnorm")
#devtools::install_github("johnwilliamsmithjr/bayesTPC")
library(bayesTPC)
library(rjags)
library(R2jags)
library(dplyr)
```

```{r lambda}
true.a<-0.001094
true.b<-0.0488
true.c<-0.609
f<-function(x,a=0.001094,b=0.0488,c=0.609){
  a*x^2-b*x+c
}
T1<-rexp(n=100,f(13))
T2<-rexp(n=100,f(17))
T3<-rexp(n=100,f(21))
T4<-rexp(n=100,f(25))
T5<-rexp(n=100,f(29))
df<-data.frame(
  T=c(rep(13,100),rep(17,100),rep(21,100),rep(25,100),rep(29,100)),
  trait=c(T1,T2,T3,T4,T5)
)
df<-N_data.list[[100]]
data <- df # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
plot(df$T,df$trait)
```

```{r mean.lambda}
 group_means <- tapply(df$trait, df$T, function(x) {
    split_values <- split(x, rep(1:10, each = 10))
    means <- sapply(split_values, mean)
    return(means)
  })
  df.mean<- data.frame(
    T=c(rep(10,10),rep(17,10),rep(21,10),rep(25,10),rep(32,10)),  # Extract T values as numeric
    trait = unlist(group_means)  # Extract means and unlist the result
  )
data <- df.mean # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
```

```{r inv.lambda}
df$inv.trait <- 1/(df$trait)
trait <- df$inv.trait
N.obs <- length(trait)
temp <- df$T
```

```{r inv.mean.lambda}
df$inv.trait <- 1/(df$trait)
  group_means.inv.mean <- tapply(df$inv.trait, df$T, function(x) {
    split_values <- split(x, rep(1:10, each = 10))
    means <- sapply(split_values, mean)
    return(means)
  })
  df.inv.mean<- data.frame(
    T=c(rep(13,10),rep(17,10),rep(21,10),rep(25,10),rep(29,10)),  # Extract T values as numeric
    trait = unlist(group_means.inv.mean)  # Extract means and unlist the result
  )
data <- df.inv.mean # this lets us reuse the same generic code: we only change this first line
trait <- data$trait
N.obs <- length(trait)
temp <- data$T
```

```{r mean.inv.lambda}
group_means.mean.inv <- tapply(df$trait, df$T, function(x) {
    split_values <- split(x, rep(1:10, each = 10))
    means <- sapply(split_values, mean)
    return(means)
  })
  df.mean.inv<- data.frame(
    T=c(rep(13,10),rep(17,10),rep(21,10),rep(25,10),rep(29,10)),  # Extract T values as numeric
    trait = unlist(group_means.mean.inv)  # Extract means and unlist the result
  )
  data<-df.mean.inv
  trait <- 1/(data$trait)
  N.obs <- length(trait)
  temp <- data$T
```

```{r normal.model}
sink("model.base.txt")
cat("model{
  # Priors
  # If mu<0, make it small number
  # And nonzero
  la ~ dnorm(0, 1/10) # has to be positive exp(1)?
  b.l ~ dnorm(0, 1/10) # Has to be positive, because function has neg sign
  c ~ dexp(0.5) # Has to be positive
  epsilon <- 0.01
  # Likelihood
  for (i in 1:N.obs){
    mu[i] <- (exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) * ((exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) > epsilon) + 
    ((exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) <= epsilon) * epsilon
    trait[i] ~ dexp(mu[i])
  }
}",file="model.base.txt")
#file.show("quad.txt")
```

```{r inverse.model}
  sink("inv.model.base.txt")
  cat("model{
  # Priors
  # If mu<0, make it small number
  # And nonzero
  la ~ dnorm(0, 1/10) # has to be positive exp(1)?
  b.l ~ dnorm(0, 1/10) # Has to be positive, because function has neg sign
  c ~ dexp(0.5) # Has to be positive
  sig ~ dexp(5000)
  sig2 <- sig^2
  tau <- 1/sig2
  #tau~dexp(10)
  epsilon <- 0.01
  # Likelihood
  for (i in 1:N.obs){
    mu[i] <- (exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) * ((exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) > epsilon) + 
    ((exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c) <= epsilon) * epsilon
    trait[i] ~ dnorm(mu[i], tau) 
  }
}",file="inv.model.base.txt")
```

```{r weibull.model}
sink("weibull.model.base.txt")
cat("model{
  #Priors
  #If mu<0, make it small number
  #And nonzero
  la~dnorm(0, 1/10) #has to be positive exp(1)?
  b.l~dnorm(0, 1/10) #Has to be positive, because function has neg sign
  c~dexp(0.5) #Has to be positive
  shape~dexp(0.001)
  #Likelihood
  for (i in 1:N.obs){
    trait[i] ~ dgen.gamma(1, lambda[i], shape) #
    lambda[i] <- (log(2))^(1/shape)/(med[i])
    med[i] <- exp(exp(la) * temp[i]^2 - exp(b.l) * temp[i] + c)
  }
}",file="weibull.model.base.txt")
#file.show("quad.txt")
```

```{r initial}
parameters <- c("la", "b.l", "c","sig")
inits<-function(){list(
  la = log(0.001),
  b.l = log(0.05),
  c = 0.6,
  sig=2
  )}

# MCMC Settings: number of posterior dist elements = [(ni - nb) / nt ] * nc
ni <- 70000 # number of iterations in each chain
nb <- 40000 # number of 'burn in' iterations to discard
nt <- 8 # thinning rate - jags saves every nt iterations in each chain
nc <- 5 # number of chains

# Bundle all data in a list for JAGS
jag.data<-list(trait = trait, N.obs = N.obs, temp = temp)
```

```{r model}
lf.fit <- jags(data=jag.data, inits=inits, parameters.to.save=parameters, 
               model.file="inv.model.base.txt", n.thin=nt, n.chains=nc, n.burnin=nb, 
               n.iter=ni, DIC=T, working.directory=getwd())
lf.fit.mcmc <- as.mcmc(lf.fit) ## makes an "mcmc" object
closeAllConnections()

mydf<-as.data.frame(lf.fit.mcmc[[3]][,c(1,2,4)])
pairs(mydf)


samp<-as.mcmc.list(lf.fit.mcmc)
hist(samp[[1]][,4],xlab="la",main="Posterior Samples of la")
abline(v=log(0.001094),col="blue",lwd=4)
hist(samp[[1]][,1],xlab="b",main="Posterior Samples of b")
abline(v=log(0.0488),col="blue",lwd=4)
hist(samp[[1]][,2],xlab="c",main="Posterior Samples of c")
abline(v=0.609,col="blue",lwd=4)
#hdi(samp[[1]][,4])[1]
```

```{r hdi.plot}
pt = samp[[1]][seq(1, nrow(samp[[1]]), 4), ]
xseq <- seq(from = 13, to = 29, length.out = 250)
ptx <- expand.grid(point = xseq, iteration = 1:nrow(pt))

# Apply the quadratic equation for each combination
ptx$value.inv <- apply(ptx, 1, function(row) {
  i <- row["iteration"]
  location <- row["point"]
  1/(exp(pt[i, 4]) * location^2 - exp(pt[i, 1]) * location + pt[i, 2])
})
ptx$value <- apply(ptx, 1, function(row) {
  i <- row["iteration"]
  location <- row["point"]
  exp(pt[i, 4]) * location^2 - exp(pt[i, 1]) * location + pt[i, 2]
})
ptx <- ptx|> mutate(trunc.eval = ifelse(ptx$value > epsilon, ptx$value, epsilon), 
                         trunc.inv = 1/trunc.eval)
ptdf <- ptx |> group_by(point) |> summarize(avg.value.inv = mean(trunc.inv), 
                                                    avg.value = mean(trunc.eval), 
                                                    med.value.inv = median(trunc.inv), 
                                                    med.value = median(trunc.eval), 
                                                    lower.hdi.inv = hdi(trunc.inv)[1], 
                                                    upper.hdi.inv = hdi(trunc.inv)[2], 
                                                    lower.hdi = hdi(trunc.eval)[1], 
                                                    upper.hdi = hdi(trunc.eval)[2])
true_curve.inv <- function(x) 1/(true.a * x^2 - true.b * x + true.c)
true_curve <- function(x) (true.a * x^2 - true.b * x + true.c)
ptdf$true_curve <- true_curve(xseq)
ptdf$true_curve.inv <- true_curve.inv(xseq)

ggplot(ptdf, aes(x = point)) +
  geom_line(aes(y = avg.value.inv), color = "black") +
  geom_ribbon(aes(ymin = lower.hdi.inv, ymax = upper.hdi.inv), fill = "darkslategray2", alpha = 0.3) +
  geom_line(aes(y = true_curve.inv), color = "violetred1", linetype = "dashed") +
  geom_point(aes(x = T, y = trait), data = df) +
  labs(title = "Mean Curve with Interval Bands and True Curve", 
       x = "Temperature", 
       y = "Lifetime") +
  theme_minimal()
```
